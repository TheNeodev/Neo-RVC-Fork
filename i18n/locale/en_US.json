{
    "### Modify model information\n> Only supported for small model files extracted from the 'weights' folder.": "### Modify model information\n> Only supported for small model files extracted from the 'weights' folder.",
    "### View model information\n> Only supported for small model files extracted from the 'weights' folder.": "### View model information\n> Only supported for small model files extracted from the 'weights' folder.",
    "### Model extraction\n> Enter the path of the large file model under the 'logs' folder.\n\nThis is useful if you want to stop training halfway and manually extract and save a small model file, or if you want to test an intermediate model.": "### Model extraction\n> Enter the path of the large file model under the 'logs' folder.\n\nThis is useful if you want to stop training halfway and manually extract and save a small model file, or if you want to test an intermediate model.",
    "### Model comparison\n> You can get model ID (long) from `View model information` below.\n\nCalculate a similarity between two models.": "### Model comparison\n> You can get model ID (long) from `View model information` below.\n\nCalculate a similarity between two models.",
    "### Model fusion\nCan be used to test timbre fusion.": "### Model fusion\nCan be used to test timbre fusion.",
    "### Step 3. Start training.\nFill in the training settings and start training the model and index.": "### Step 3. Start training.\nFill in the training settings and start training the model and index.",
    "### Step 2. Audio processing. \n#### 1. Slicing.\nAutomatically traverse all files in the training folder that can be decoded into audio and perform slice normalization. Generates 2 wav folders in the experiment directory. Currently, only single-singer/speaker training is supported.": "### Step 2. Audio processing. \n#### 1. Slicing.\nAutomatically traverse all files in the training folder that can be decoded into audio and perform slice normalization. Generates 2 wav folders in the experiment directory. Currently, only single-singer/speaker training is supported.",
    "#### 2. Feature extraction.\nUse CPU to extract pitch (if the model has pitch), use GPU to extract features (select GPU index).": "#### 2. Feature extraction.\nUse CPU to extract pitch (if the model has pitch), use GPU to extract features (select GPU index).",
    "If >=3: apply median filtering to the harvested pitch results. The value represents the filter radius and can reduce breathiness.": "If >=3: apply median filtering to the harvested pitch results. The value represents the filter radius and can reduce breathiness.",
    "ID of model A (long)": "ID of model A (long)",
    "Weight (w) for Model A": "Weight (w) for Model A",
    "Path to Model A": "Path to Model A",
    "ID of model B (long)": "ID of model B (long)",
    "Path to Model B": "Path to Model B",
    "F0 curve file (optional). One pitch per line. Replaces the default F0 and pitch modulation": "F0 curve file (optional). One pitch per line. Replaces the default F0 and pitch modulation",
    "ID(short)": "ID(short)",
    "ID(long)": "ID(long)",
    "None": "None",
    "Export Onnx": "Export Onnx",
    "Onnx Export Path": "Onnx Export Path",
    "RVC Model Path": "RVC Model Path",
    "Unknown": "Unknown",
    "ckpt Processing": "ckpt Processing",
    "Number of CPU processes used for harvest pitch algorithm": "Number of CPU processes used for harvest pitch algorithm",
    "index path cannot contain unicode characters": "index path cannot contain unicode characters",
    "pth path cannot contain unicode characters": "pth path cannot contain unicode characters",
    "Enter the GPU index(es) separated by '-', e.g., 0-0-1 to use 2 processes in GPU0 and 1 process in GPU1": "Enter the GPU index(es) separated by '-', e.g., 0-0-1 to use 2 processes in GPU0 and 1 process in GPU1",
    "Step 1: Processing data": "Step 1: Processing data",
    "step2:Pitch extraction & feature extraction": "step2:Pitch extraction & feature extraction",
    "Step 3a: Model training started": "Step 3a: Model training started",
    "One-click training": "One-click training",
    "Hidden": "Hidden",
    "Multiple audio files can also be imported. If a folder path exists, this input is ignored.": "Multiple audio files can also be imported. If a folder path exists, this input is ignored.",
    "Batch processing for vocal accompaniment separation using the UVR5 model.<br>Example of a valid folder path format: D:\\path\\to\\input\\folder (copy it from the file manager address bar).<br>The model is divided into three categories:<br>1. Preserve vocals: Choose this option for audio without harmonies. It preserves vocals better than HP5. It includes two built-in models: HP2 and HP3. HP3 may slightly leak accompaniment but preserves vocals slightly better than HP2.<br>2. Preserve main vocals only: Choose this option for audio with harmonies. It may weaken the main vocals. It includes one built-in model: HP5.<br>3. De-reverb and de-delay models (by FoxJoy):<br>  (1) MDX-Net: The best choice for stereo reverb removal but cannot remove mono reverb;<br>&emsp;(234) DeEcho: Removes delay effects. Aggressive mode removes more thoroughly than Normal mode. DeReverb additionally removes reverb and can remove mono reverb, but not very effectively for heavily reverberated high-frequency content.<br>De-reverb/de-delay notes:<br>1. The processing time for the DeEcho-DeReverb model is approximately twice as long as the other two DeEcho models.<br>2. The MDX-Net-Dereverb model is quite slow.<br>3. The recommended cleanest configuration is to apply MDX-Net first and then DeEcho-Aggressive.": "Batch processing for vocal accompaniment separation using the UVR5 model.<br>Example of a valid folder path format: D:\\path\\to\\input\\folder (copy it from the file manager address bar).<br>The model is divided into three categories:<br>1. Preserve vocals: Choose this option for audio without harmonies. It preserves vocals better than HP5. It includes two built-in models: HP2 and HP3. HP3 may slightly leak accompaniment but preserves vocals slightly better than HP2.<br>2. Preserve main vocals only: Choose this option for audio with harmonies. It may weaken the main vocals. It includes one built-in model: HP5.<br>3. De-reverb and de-delay models (by FoxJoy):<br>  (1) MDX-Net: The best choice for stereo reverb removal but cannot remove mono reverb;<br>&emsp;(234) DeEcho: Removes delay effects. Aggressive mode removes more thoroughly than Normal mode. DeReverb additionally removes reverb and can remove mono reverb, but not very effectively for heavily reverberated high-frequency content.<br>De-reverb/de-delay notes:<br>1. The processing time for the DeEcho-DeReverb model is approximately twice as long as the other two DeEcho models.<br>2. The MDX-Net-Dereverb model is quite slow.<br>3. The recommended cleanest configuration is to apply MDX-Net first and then DeEcho-Aggressive.",
    "Read from model": "Read from model",
    "Enter the GPU index(es) separated by '-', e.g., 0-1-2 to use GPU 0, 1, and 2": "Enter the GPU index(es) separated by '-', e.g., 0-1-2 to use GPU 0, 1, and 2",
    "Vocals/Accompaniment Separation & Reverberation Removal": "Vocals/Accompaniment Separation & Reverberation Removal",
    "Choose sample rate of the model": "Choose sample rate of the model",
    "Choose sample rate of the device": "Choose sample rate of the device",
    "Save name": "Save name",
    "Save file name (default: same as the source file)": "Save file name (default: same as the source file)",
    "Saved model name (without extension)": "Saved model name (without extension)",
    "Save frequency (save_every_epoch)": "Save frequency (save_every_epoch)",
    "Protect voiceless consonants and breath sounds to prevent artifacts such as tearing in electronic music. Set to 0.5 to disable. Decrease the value to increase protection, but it may reduce indexing accuracy": "Protect voiceless consonants and breath sounds to prevent artifacts such as tearing in electronic music. Set to 0.5 to disable. Decrease the value to increase protection, but it may reduce indexing accuracy",
    "Information": "Information",
    "Modify": "Modify",
    "Stop audio conversion": "Stop audio conversion",
    "All processes have been completed!": "All processes have been completed!",
    "Resonating offset": "Resonating offset",
    "Refresh voice list and index path": "Refresh voice list and index path",
    "Load model": "Load model",
    "Load pre-trained base model D path": "Load pre-trained base model D path",
    "Load pre-trained base model G path": "Load pre-trained base model G path",
    "Single inference": "Single inference",
    "Unload model to save GPU memory": "Unload model to save GPU memory",
    "Transpose (integer, number of semitones, raise by an octave: 12, lower by an octave: -12)": "Transpose (integer, number of semitones, raise by an octave: 12, lower by an octave: -12)",
    "Resample the output audio in post-processing to the final sample rate. Set to 0 for no resampling": "Resample the output audio in post-processing to the final sample rate. Set to 0 for no resampling",
    "No": "No",
    "Enable phase vocoder": "Enable phase vocoder",
    "Response threshold": "Response threshold",
    "loudness factor": "loudness factor",
    "Process data": "Process data",
    "Fail": "Fail",
    "Actually calculated": "Actually calculated",
    "Export Onnx Model": "Export Onnx Model",
    "Export file format": "Export file format",
    "Sealing date": "Sealing date",
    "FAQ (Frequently Asked Questions)": "FAQ (Frequently Asked Questions)",
    "General settings": "General settings",
    "Start audio conversion": "Start audio conversion",
    "The audio file to be processed": "The audio file to be processed",
    "Unfortunately, there is no compatible GPU available to support your training.": "Unfortunately, there is no compatible GPU available to support your training.",
    "Performance settings": "Performance settings",
    "Total training epochs (total_epoch)": "Total training epochs (total_epoch)",
    "Successfully built index into": "Successfully built index into",
    "Batch inference": "Batch inference",
    "Batch conversion. Enter the folder containing the audio files to be converted or upload multiple audio files. The converted audio will be output in the specified folder (default: 'opt').": "Batch conversion. Enter the folder containing the audio files to be converted or upload multiple audio files. The converted audio will be output in the specified folder (default: 'opt').",
    "Specify the output folder for vocals": "Specify the output folder for vocals",
    "Specify output folder": "Specify output folder",
    "Specify the output folder for accompaniment": "Specify the output folder for accompaniment",
    "Inference time (ms)": "Inference time (ms)",
    "Inferencing voice": "Inferencing voice",
    "Extract": "Extract",
    "Number of CPU processes used for pitch extraction and data processing": "Number of CPU processes used for pitch extraction and data processing",
    "Not exist": "Not exist",
    "Yes": "Yes",
    "Save only the latest '.ckpt' file to save disk space": "Save only the latest '.ckpt' file to save disk space",
    "Save a small final model to the 'weights' folder at each save point": "Save a small final model to the 'weights' folder at each save point",
    "Cache all training sets to GPU memory. Caching small datasets (less than 10 minutes) can speed up training, but caching large datasets will consume a lot of GPU memory and may not provide much speed improvement": "Cache all training sets to GPU memory. Caching small datasets (less than 10 minutes) can speed up training, but caching large datasets will consume a lot of GPU memory and may not provide much speed improvement",
    "GPU Information": "GPU Information",
    "Exist": "Exist",
    "This software is open source under the MIT license. The author does not have any control over the software. Users who use the software and distribute the sounds exported by the software are solely responsible. <br>If you do not agree with this clause, you cannot use or reference any codes and files within the software package. See the root directory <b>Agreement-LICENSE.txt</b> for details.": "This software is open source under the MIT license. The author does not have any control over the software. Users who use the software and distribute the sounds exported by the software are solely responsible. <br>If you do not agree with this clause, you cannot use or reference any codes and files within the software package. See the root directory <b>Agreement-LICENSE.txt</b> for details.",
    "View": "View",
    "Search feature ratio (controls accent strength, too high has artifacting)": "Search feature ratio (controls accent strength, too high has artifacting)",
    "Model": "Model",
    "Model Author": "Model Author",
    "Model Author (Nullable)": "Model Author (Nullable)",
    "Model info": "Model info",
    "Model name": "Model name",
    "Model Inference": "Model Inference",
    "Whether the model has pitch guidance": "Whether the model has pitch guidance",
    "Whether the model has pitch guidance (required for singing, optional for speech)": "Whether the model has pitch guidance (required for singing, optional for speech)",
    "Whether the model has pitch guidance (1: yes, 0: no)": "Whether the model has pitch guidance (1: yes, 0: no)",
    "Model architecture version": "Model architecture version",
    "Path to Model": "Path to Model",
    "Batch size per GPU": "Batch size per GPU",
    "Fade length": "Fade length",
    "Version": "Version",
    "Feature extraction": "Feature extraction",
    "Path to the feature index file. Leave blank to use the selected result from the dropdown": "Path to the feature index file. Leave blank to use the selected result from the dropdown",
    "Takeover WASAPI device": "Takeover WASAPI device",
    "Target sample rate": "Target sample rate",
    "Similarity": "Similarity",
    "Similarity (from 0 to 1)": "Similarity (from 0 to 1)",
    "Algorithmic delays (ms)": "Algorithmic delays (ms)",
    "Auto-detect index path and select from the dropdown": "Auto-detect index path and select from the dropdown",
    "Fusion": "Fusion",
    "Model information to be modified": "Model information to be modified",
    "Model information to be placed": "Model information to be placed",
    "Calculate": "Calculate",
    "Train": "Train",
    "Train model": "Train model",
    "Train feature index": "Train feature index",
    "Training complete. You can check the training logs in the console or the 'train.log' file under the experiment folder.": "Training complete. You can check the training logs in the console or the 'train.log' file under the experiment folder.",
    "Device type": "Device type",
    "Please specify the speaker/singer ID": "Please specify the speaker/singer ID",
    "Please choose the .index file": "Please choose the .index file",
    "Please choose the .pth file": "Please choose the .pth file",
    "Select Speaker/Singer ID": "Select Speaker/Singer ID",
    "Convert": "Convert",
    "Enter the experiment name": "Enter the experiment name",
    "Enter the path of the audio folder to be processed": "Enter the path of the audio folder to be processed",
    "Enter the path of the audio folder to be processed (copy it from the address bar of the file manager)": "Enter the path of the audio folder to be processed (copy it from the address bar of the file manager)",
    "Adjust the volume envelope scaling. Closer to 0, the more it mimicks the volume of the original vocals. Can help mask noise and make volume sound more natural when set relatively low. Closer to 1 will be more of a consistently loud volume": "Adjust the volume envelope scaling. Closer to 0, the more it mimicks the volume of the original vocals. Can help mask noise and make volume sound more natural when set relatively low. Closer to 1 will be more of a consistently loud volume",
    "Input voice monitor": "Input voice monitor",
    "Enter the path of the training folder": "Enter the path of the training folder",
    "Input device": "Input device",
    "Input noise reduction": "Input noise reduction",
    "Output information": "Output information",
    "Output converted voice": "Output converted voice",
    "Output device": "Output device",
    "Output noise reduction": "Output noise reduction",
    "Export audio (click on the three dots in the lower right corner to download)": "Export audio (click on the three dots in the lower right corner to download)",
    "Select the .index file": "Select the .index file",
    "Select the .pth file": "Select the .pth file",
    "Select the pitch extraction algorithm ('pm': faster extraction but lower-quality speech; 'harvest': better bass but extremely slow; 'crepe': better quality but GPU intensive), 'rmvpe': best quality, and little GPU requirement": "Select the pitch extraction algorithm ('pm': faster extraction but lower-quality speech; 'harvest': better bass but extremely slow; 'crepe': better quality but GPU intensive), 'rmvpe': best quality, and little GPU requirement",
    "Select the pitch extraction algorithm: when extracting singing, you can use 'pm' to speed up. For high-quality speech with fast performance, but worse CPU usage, you can use 'dio'. 'harvest' results in better quality but is slower.  'rmvpe' has the best results and consumes less CPU/GPU": "Select the pitch extraction algorithm: when extracting singing, you can use 'pm' to speed up. For high-quality speech with fast performance, but worse CPU usage, you can use 'dio'. 'harvest' results in better quality but is slower.  'rmvpe' has the best results and consumes less CPU/GPU",
    "Sampling rate": "Sampling rate",
    "Sample length": "Sample length",
    "Reload device list": "Reload device list",
    "Link index to outside folder": "Link index to outside folder",
    "Pitch settings": "Pitch settings",
    "Audio device": "Audio device",
    "Pitch guidance (f0)": "Pitch guidance (f0)",
    "Pitch detection algorithm": "Pitch detection algorithm",
    "Extra inference time": "Extra inference time"
}