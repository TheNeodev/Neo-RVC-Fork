{
    "### Modify model information\n> Only supported for small model files extracted from the 'weights' folder.": "### Modificar informações do modelo\n> Suportado apenas para arquivos de modelo pequenos extraídos da pasta 'weights'.",
    "### View model information\n> Only supported for small model files extracted from the 'weights' folder.": "### Exibir informações do modelo\n> Suportado apenas para arquivos de modelo pequenos extraídos da pasta 'weights'.",
    "### Model extraction\n> Enter the path of the large file model under the 'logs' folder.\n\nThis is useful if you want to stop training halfway and manually extract and save a small model file, or if you want to test an intermediate model.": "### Extração do modelo\n> Insira o caminho do modelo de arquivo grande na pasta 'logs'.\n\nIsso é útil se você quiser interromper o treinamento no meio do caminho e extrair e salvar manualmente um arquivo de modelo pequeno, ou se quiser testar um modelo intermediário.",
    "### Model comparison\n> You can get model ID (long) from `View model information` below.\n\nCalculate a similarity between two models.": "### 模型比较\n> 模型ID(长)请于下方`查看模型信息`中获得\n\n可用于比较两模型推理相似度",
    "### Model fusion\nCan be used to test timbre fusion.": "### A fusão modelo\nPode ser usada para testar a fusão do timbre.",
    "### Step 3. Start training.\nFill in the training settings and start training the model and index.": "### 第三步 开始训练\n填写训练设置, 开始训练模型和索引.",
    "### Step 2. Audio processing. \n#### 1. Slicing.\nAutomatically traverse all files in the training folder that can be decoded into audio and perform slice normalization. Generates 2 wav folders in the experiment directory. Currently, only single-singer/speaker training is supported.": "### 第二步 音频处理\n#### 1. 音频切片\n自动遍历训练文件夹下所有可解码成音频的文件并进行切片归一化, 在实验目录下生成2个wav文件夹; 暂时只支持单人训练.",
    "#### 2. Feature extraction.\nUse CPU to extract pitch (if the model has pitch), use GPU to extract features (select GPU index).": "#### 2. 特征提取\n使用CPU提取音高(如果模型带音高), 使用GPU提取特征(选择卡号).",
    "If >=3: apply median filtering to the harvested pitch results. The value represents the filter radius and can reduce breathiness.": ">=3, use o filtro mediano para o resultado do reconhecimento do tom da heverst, e o valor é o raio do filtro, que pode enfraquecer o mudo.",
    "ID of model A (long)": "A模型ID(长)",
    "Weight (w) for Model A": "Peso (w) para o modelo A:",
    "Path to Model A": "Caminho para o Modelo A:",
    "ID of model B (long)": "B模型ID(长)",
    "Path to Model B": "Caminho para o Modelo B:",
    "F0 curve file (optional). One pitch per line. Replaces the default F0 and pitch modulation": "Arquivo de curva F0 (opcional). Um arremesso por linha. Substitui a modulação padrão F0 e tom:",
    "ID(short)": "ID(短)",
    "ID(long)": "ID(长)",
    "None": "None",
    "Export Onnx": "Exportar Onnx",
    "Onnx Export Path": "Caminho de exportação ONNX:",
    "RVC Model Path": "Caminho do Modelo RVC:",
    "Unknown": "Unknown",
    "ckpt Processing": "processamento ckpt",
    "Number of CPU processes used for harvest pitch algorithm": "Número de processos harvest",
    "index path cannot contain unicode characters": "O caminho do arquivo de Index não pode conter caracteres chineses",
    "pth path cannot contain unicode characters": "o caminho do arquivo pth não pode conter caracteres chineses",
    "Enter the GPU index(es) separated by '-', e.g., 0-0-1 to use 2 processes in GPU0 and 1 process in GPU1": "Configuração do número do cartão rmvpe: Use - para separar os números dos cartões de entrada de diferentes processos. Por exemplo, 0-0-1 é usado para executar 2 processos no cartão 0 e 1 processo no cartão 1.",
    "Step 1: Processing data": "Etapa 1: Processamento de dados",
    "step2:Pitch extraction & feature extraction": "step2:正在提取音高&正在提取特征",
    "Step 3a: Model training started": "Etapa 3a: Treinamento do modelo iniciado",
    "One-click training": "Treinamento com um clique",
    "Hidden": "不显示",
    "Multiple audio files can also be imported. If a folder path exists, this input is ignored.": "Você também pode inserir arquivos de áudio em lotes. Escolha uma das duas opções. É dada prioridade à leitura da pasta.",
    "Batch processing for vocal accompaniment separation using the UVR5 model.<br>Example of a valid folder path format: D:\\path\\to\\input\\folder (copy it from the file manager address bar).<br>The model is divided into three categories:<br>1. Preserve vocals: Choose this option for audio without harmonies. It preserves vocals better than HP5. It includes two built-in models: HP2 and HP3. HP3 may slightly leak accompaniment but preserves vocals slightly better than HP2.<br>2. Preserve main vocals only: Choose this option for audio with harmonies. It may weaken the main vocals. It includes one built-in model: HP5.<br>3. De-reverb and de-delay models (by FoxJoy):<br>  (1) MDX-Net: The best choice for stereo reverb removal but cannot remove mono reverb;<br>&emsp;(234) DeEcho: Removes delay effects. Aggressive mode removes more thoroughly than Normal mode. DeReverb additionally removes reverb and can remove mono reverb, but not very effectively for heavily reverberated high-frequency content.<br>De-reverb/de-delay notes:<br>1. The processing time for the DeEcho-DeReverb model is approximately twice as long as the other two DeEcho models.<br>2. The MDX-Net-Dereverb model is quite slow.<br>3. The recommended cleanest configuration is to apply MDX-Net first and then DeEcho-Aggressive.": "Processamento em lote para separação de acompanhamento vocal usando o modelo UVR5.<br>Exemplo de um formato de caminho de pasta válido: D:\\caminho\\para a pasta\\entrada\\ (copie-o da barra de endereços do gerenciador de arquivos).<br>O modelo é dividido em três categorias:<br>1. Preservar vocais: Escolha esta opção para áudio sem harmonias. Ele preserva os vocais melhor do que o HP5. Inclui dois modelos integrados: HP2 e HP3. O HP3 pode vazar ligeiramente o acompanhamento, mas preserva os vocais um pouco melhor do que o HP2.<br>2 Preservar apenas os vocais principais: Escolha esta opção para áudio com harmonias. Isso pode enfraquecer os vocais principais. Ele inclui um modelo embutido: HP5.<br>3. Modelos de de-reverb e de-delay (por FoxJoy):<br>  (1) MDX-Net: A melhor escolha para remoção de reverb estéreo, mas não pode remover reverb mono;<br>&emsp;(234) DeEcho: Remove efeitos de atraso. O modo agressivo remove mais completamente do que o modo normal. O DeReverb também remove reverb e pode remover reverb mono, mas não de forma muito eficaz para conteúdo de alta frequência fortemente reverberado.<br>Notas de de-reverb/de-delay:<br>1. O tempo de processamento para o modelo DeEcho-DeReverb é aproximadamente duas vezes maior que os outros dois modelos DeEcho.<br>2 O modelo MDX-Net-Dereverb é bastante lento.<br>3. A configuração mais limpa recomendada é aplicar MDX-Net primeiro e depois DeEcho-Aggressive.",
    "Read from model": "从模型中读取",
    "Enter the GPU index(es) separated by '-', e.g., 0-1-2 to use GPU 0, 1, and 2": "Digite o (s) índice(s) da GPU separados por '-', por exemplo, 0-1-2 para usar a GPU 0, 1 e 2:",
    "Vocals/Accompaniment Separation & Reverberation Removal": "UVR5",
    "Choose sample rate of the model": "使用模型采样率",
    "Choose sample rate of the device": "使用设备采样率",
    "Save name": "Salvar nome",
    "Save file name (default: same as the source file)": "Salvar nome do arquivo (padrão: igual ao arquivo de origem):",
    "Saved model name (without extension)": "Nome do modelo salvo (sem extensão):",
    "Save frequency (save_every_epoch)": "Faça backup a cada # de Epoch:",
    "Protect voiceless consonants and breath sounds to prevent artifacts such as tearing in electronic music. Set to 0.5 to disable. Decrease the value to increase protection, but it may reduce indexing accuracy": "Proteja consoantes sem voz e sons respiratórios, evite artefatos como quebra de som eletrônico e desligue-o quando estiver cheio de 0,5. Diminua-o para aumentar a proteção, mas pode reduzir o efeito de indexação:",
    "Information": "信息",
    "Modify": "Editar",
    "Stop audio conversion": "Conversão de áudio",
    "All processes have been completed!": "Todos os processos foram concluídos!",
    "Formant offset": "共振偏移",
    "Refresh voice list and index path": "Atualizar lista de voz e caminho do Index",
    "Load model": "Modelo",
    "Load pre-trained base model D path": "Carregue o caminho D do modelo base pré-treinado:",
    "Load pre-trained base model G path": "Carregue o caminho G do modelo base pré-treinado:",
    "Single inference": "Único",
    "Unload model to save GPU memory": "Descarregue a voz para liberar a memória da GPU:",
    "Transpose (integer, number of semitones, raise by an octave: 12, lower by an octave: -12)": "Mude o tom aqui. Se a voz for do mesmo sexo, não é necessario alterar (12 caso seja Masculino para feminino, -12 caso seja ao contrário).",
    "Resample the output audio in post-processing to the final sample rate. Set to 0 for no resampling": "Reamostragem pós-processamento para a taxa de amostragem final, 0 significa sem reamostragem:",
    "No": "Não",
    "Enable phase vocoder": "启用相位声码器",
    "Response threshold": "Limiar de resposta",
    "Loudness factor": "Fator de volume",
    "Process data": "Processar o Conjunto de Dados",
    "Fail": "失败",
    "Actually calculated": "实际计算",
    "Export Onnx Model": "Exportar Modelo Onnx",
    "Export file format": "Qual formato de arquivo você prefere?",
    "Sealing date": "封装时间",
    "FAQ (Frequently Asked Questions)": "FAQ (Perguntas frequentes)",
    "General settings": "Configurações gerais",
    "Start audio conversion": "Iniciar conversão de áudio",
    "The audio file to be processed": "待处理音频文件",
    "Unfortunately, there is no compatible GPU available to support your training.": "Infelizmente, não há GPU compatível disponível para apoiar o seu treinamento.",
    "Performance settings": "Configurações de desempenho.",
    "Total training epochs (total_epoch)": "Número total de ciclos(epoch) de treino (se escolher um valor alto demais, o seu modelo parecerá terrivelmente sobretreinado):",
    "Successfully built index into": "成功构建索引到",
    "Batch inference": "Conversão em Lote",
    "Batch conversion. Enter the folder containing the audio files to be converted or upload multiple audio files. The converted audio will be output in the specified folder (default: 'opt').": "Conversão em Massa.",
    "Specify the output folder for vocals": "Especifique a pasta de saída para vocais:",
    "Specify output folder": "Especifique a pasta de saída:",
    "Specify the output folder for accompaniment": "Informar a pasta de saída para acompanhamento:",
    "Inference time (ms)": "Tempo de inferência (ms)",
    "Inferencing voice": "Escolha o seu Modelo:",
    "Extract": "Extrato",
    "Number of CPU processes used for pitch extraction and data processing": "Número de processos de CPU usados para extração de tom e processamento de dados:",
    "Not exist": "无",
    "Yes": "Sim",
    "Save only the latest '.ckpt' file to save disk space": "Só deve salvar apenas o arquivo ckpt mais recente para economizar espaço em disco:",
    "Save a small final model to the 'weights' folder at each save point": "Salve um pequeno modelo final na pasta 'weights' em cada ponto de salvamento:",
    "Cache all training sets to GPU memory. Caching small datasets (less than 10 minutes) can speed up training, but caching large datasets will consume a lot of GPU memory and may not provide much speed improvement": "Se deve armazenar em cache todos os conjuntos de treinamento na memória de vídeo. Pequenos dados com menos de 10 minutos podem ser armazenados em cache para acelerar o treinamento, e um cache de dados grande irá explodir a memória de vídeo e não aumentar muito a velocidade:",
    "GPU Information": "Informações da GPU",
    "Exist": "有",
    "This software is open source under the MIT license. The author does not have any control over the software. Users who use the software and distribute the sounds exported by the software are solely responsible. <br>If you do not agree with this clause, you cannot use or reference any codes and files within the software package. See the root directory <b>Agreement-LICENSE.txt</b> for details.": "<center>The Mangio-RVC 💻 | Tradução por Krisp e Rafael Godoy Ebert | AI HUB BRASIL<br> Este software é de código aberto sob a licença MIT. O autor não tem qualquer controle sobre o software. Aqueles que usam o software e divulgam os sons exportados pelo software são totalmente responsáveis. <br>Se você não concorda com este termo, você não pode usar ou citar nenhum código e arquivo no pacote de software. Para obter detalhes, consulte o diretório raiz <b>O acordo a ser seguido para uso <a href='https://raw.githubusercontent.com/fumiama/Retrieval-based-Voice-Conversion-WebUI/main/LICENSE' target='_blank'>LICENSE</a></b></center>",
    "View": "Visualizar",
    "Search feature ratio (controls accent strength, too high has artifacting)": "Taxa de recurso de recuperação:",
    "Model": "Modelo",
    "Model Author": "模型作者",
    "Model Author (Nullable)": "模型作者(可空)",
    "Model info": "模型信息",
    "Model name": "模型名",
    "Model Inference": "Inference",
    "Whether the model has pitch guidance": "Se o modelo tem orientação de tom:",
    "Whether the model has pitch guidance (required for singing, optional for speech)": "Se o modelo tem orientação de tom (necessário para cantar, opcional para fala):",
    "Whether the model has pitch guidance (1: yes, 0: no)": "Se o modelo tem orientação de passo (1: sim, 0: não):",
    "Model architecture version": "Versão:",
    "Path to Model": "Caminho para o Modelo:",
    "Batch size per GPU": "Batch Size (DEIXE COMO ESTÁ a menos que saiba o que está fazendo, no Colab pode deixar até 20!):",
    "Fade length": "Comprimento de desvanecimento",
    "Version": "Versão",
    "Feature extraction": "Extrair Tom",
    "Path to the feature index file. Leave blank to use the selected result from the dropdown": "Caminho para o arquivo de Index. Deixe em branco para usar o resultado selecionado no menu debaixo:",
    "Takeover WASAPI device": "独占 WASAPI 设备",
    "Target sample rate": "Taxa de amostragem:",
    "Similarity": "相似度",
    "Similarity (from 0 to 1)": "相似度(0到1)",
    "Algorithmic delays (ms)": "Atrasos algorítmicos (ms)",
    "Auto-detect index path and select from the dropdown": "Detecte automaticamente o caminho do Index e selecione no menu suspenso:",
    "Fusion": "Fusão",
    "Model information to be modified": "Informações do modelo a ser modificado:",
    "Model information to be placed": "Informações do modelo a ser colocado:",
    "Calculate": "计算",
    "Train": "Treinar",
    "Train model": "Treinar Modelo",
    "Train feature index": "Treinar Index",
    "Training complete. You can check the training logs in the console or the 'train.log' file under the experiment folder.": "Após o término do treinamento, você pode verificar o log de treinamento do console ou train.log na pasta de experimentos",
    "Device type": "设备类型",
    "Please specify the speaker/singer ID": "Especifique o ID do locutor/cantor:",
    "Please choose the .index file": "Selecione o arquivo de Index",
    "Please choose the .pth file": "Selecione o arquivo pth",
    "Select Speaker/Singer ID": "Selecione Palestrantes/Cantores ID:",
    "Convert": "Converter",
    "Enter the experiment name": "Nome da voz:",
    "Enter the path of the audio folder to be processed": "Caminho da pasta de áudio a ser processada:",
    "Enter the path of the audio folder to be processed (copy it from the address bar of the file manager)": "Caminho da pasta de áudio a ser processada (copie-o da barra de endereços do gerenciador de arquivos):",
    "Adjust the volume envelope scaling. Closer to 0, the more it mimicks the volume of the original vocals. Can help mask noise and make volume sound more natural when set relatively low. Closer to 1 will be more of a consistently loud volume": "O envelope de volume da fonte de entrada substitui a taxa de fusão do envelope de volume de saída, quanto mais próximo de 1, mais o envelope de saída é usado:",
    "Input voice monitor": "Monitoramento de entrada",
    "Enter the path of the training folder": "Caminho da pasta de treinamento:",
    "Input device": "Dispositivo de entrada",
    "Input noise reduction": "Redução de ruído de entrada",
    "Output information": "Informação de saída",
    "Output converted voice": "Mudança de voz de saída",
    "Output device": "Dispositivo de saída",
    "Output noise reduction": "Redução de ruído de saída",
    "Export audio (click on the three dots in the lower right corner to download)": "Exportar áudio (clique nos três pontos no canto inferior direito para baixar)",
    "Select the .index file": "Selecione o Index",
    "Select the .pth file": "Selecione o Arquivo",
    "Select the pitch extraction algorithm ('pm': faster extraction but lower-quality speech; 'harvest': better bass but extremely slow; 'crepe': better quality but GPU intensive), 'rmvpe': best quality, and little GPU requirement": "Selecione o algoritmo de extração de tom \n'pm': extração mais rápida, mas discurso de qualidade inferior; \n'harvest': graves melhores, mas extremamente lentos; \n'harvest': melhor qualidade, mas extração mais lenta); 'crepe': melhor qualidade, mas intensivo em GPU; 'magio-crepe': melhor opção; 'RMVPE': um modelo robusto para estimativa de afinação vocal em música polifônica;",
    "Select the pitch extraction algorithm: when extracting singing, you can use 'pm' to speed up. For high-quality speech with fast performance, but worse CPU usage, you can use 'dio'. 'harvest' results in better quality but is slower.  'rmvpe' has the best results and consumes less CPU/GPU": "Selecione o algoritmo de extração de tom \n'pm': extração mais rápida, mas discurso de qualidade inferior; \n'harvest': graves melhores, mas extremamente lentos; \n'crepe': melhor qualidade (mas intensivo em GPU);\n rmvpe tem o melhor efeito e consome menos CPU/GPU.",
    "Sampling rate": "采样率",
    "Sample length": "Comprimento da Amostra",
    "Reload device list": "Recarregar lista de dispositivos",
    "Link index to outside folder": "链接索引到外部",
    "Pitch settings": "Configurações de tom",
    "Audio device": "音频设备",
    "Pitch guidance (f0)": "音高引导(f0)",
    "Pitch detection algorithm": "Algoritmo de detecção de pitch",
    "Extra inference time": "Tempo extra de inferência"
}